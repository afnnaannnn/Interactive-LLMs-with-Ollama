# kapitala-ext README

This vscode extension features a powerful UI to interact with ollama to use LLMs models on your local system.

## Features

- Easy to use and functional extension to use within your vscode
- Web interface helps if you don't want the CLI/Terminal to input or see your output text

## Requirements

Firstly, install ollama on your windows/mac/linux machine then follow the documented instructions on ollama website for the model you're trying to run locally.  
E.g.,
https://ollama.com/library/deepseek-r1


## Known Issues

- None so far

## Release Notes

- Fixed certain issues while tapping the button to feed the input text to the model


